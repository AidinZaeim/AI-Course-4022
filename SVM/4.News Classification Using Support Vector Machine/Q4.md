# News Classification Using Support Vector Machine (SVM)
## Introduction
News classification is an essential task in natural language processing, allowing us to categorize news articles into predefined topics. The aim of this project is to develop a machine learning model that can effectively classify news articles into different categories using Support Vector Machine (SVM). This document outlines the process of building a news classifier using an SVM with text data preprocessing and Term Frequency-Inverse Document Frequency (TF-IDF) vectorization.

### Step-by-Step Explanation
Import Necessary Libraries
We begin by importing the necessary libraries for data manipulation, text processing, machine learning, and evaluation. This includes NumPy for numerical operations, Matplotlib for visualization, Seaborn for enhanced visualizations, and several modules from scikit-learn for machine learning tasks.

### Create the Dataset
The dataset used in this project is the "20 Newsgroups" dataset, which contains news articles from 20 different newsgroups. For simplicity, we select four categories: 'alt.atheism', 'soc.religion.christian', 'comp.graphics', and 'sci.med'. The dataset is loaded using the fetch_20newsgroups function from scikit-learn.

### Preprocess the Text Data
The text data is preprocessed by converting it into numerical feature vectors using TF-IDF vectorization. TF-IDF (Term Frequency-Inverse Document Frequency) reflects the importance of a word in a document relative to the entire corpus, capturing the significance of words in the context of the dataset.

### Train the SVM Model
We train a Support Vector Machine (SVM) with different kernels ('rbf', 'sigmoid', 'linear', 'poly') on the training data. SVMs are powerful classifiers that work well with high-dimensional data, making them suitable for text classification tasks.

### Test the Model
The trained SVM models are used to predict the labels of the test data.

### Evaluate the Model
The models' performance is evaluated using the accuracy metric. The accuracy scores for different kernels are printed to compare their performance.

### Visualize the Results
To visualize the classification results, we reduce the dimensionality of the TF-IDF vectors to 2D using Truncated SVD. We then plot the test data in the reduced 2D space with the predicted labels to illustrate the classification performance.

### Why We Chose This Method and Kernels
Different kernels were chosen for the SVM to evaluate their performance on the news classification task. The linear kernel is often a good choice for text classification tasks due to its simplicity and efficiency. Other kernels like 'rbf', 'sigmoid', and 'poly' are also evaluated to explore their effectiveness in capturing non-linear relationships in the data.

### Functionality and Dataset
The functionality of this project involves preprocessing text data, transforming it using TF-IDF vectorization, training SVM classifiers with different kernels, evaluating their performance, and visualizing the classification results. The dataset used is the "20 Newsgroups," which provides a diverse set of news articles for developing and testing a news classification model.

## The `Accuracy` for all of the kernels was `92.07723035952064`